name: Update Terraform Provider Dashboard

on:
  # Run weekly on Thursdays at 6 AM UTC
  schedule:
    - cron: '0 6 * * 4'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      tier:
        description: 'Provider tier to scan'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - official
          - partner
      limit:
        description: 'Max providers to scan (0 = no limit)'
        required: false
        default: '0'
        type: string
      incremental:
        description: 'Incremental mode (only scan changed providers)'
        required: false
        default: true
        type: boolean

# Sets permissions for GitHub Pages deployment and committing data
permissions:
  contents: write
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Restore cached provider data
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            terraform_providers.csv
            terraform_providers_details.json
            data/snapshots
            data/history.json
          key: provider-data-${{ hashFiles('terraform_providers.csv') }}
          restore-keys: |
            provider-data-

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run provider scanner
        run: |
          # Build command based on inputs (no --no-github for accurate v5/v6 detection)
          CMD="python3 tf_provider_scanner.py --output terraform_providers.csv"
          
          # Add tier filter (default: all providers)
          TIER="${{ github.event.inputs.tier || 'all' }}"
          if [ "$TIER" != "all" ]; then
            CMD="$CMD --tier $TIER"
          fi
          
          # Add limit if specified
          LIMIT="${{ github.event.inputs.limit || '0' }}"
          if [ "$LIMIT" != "0" ]; then
            CMD="$CMD --limit $LIMIT"
          fi
          
          # Add incremental mode (default for scheduled runs)
          INCREMENTAL="${{ github.event.inputs.incremental }}"
          if [ "$INCREMENTAL" != "false" ] && [ -f "terraform_providers.csv" ]; then
            CMD="$CMD --incremental"
            echo "Incremental mode enabled - will only scan changed providers"
          fi
          
          # Always save snapshot since we run weekly now
          CMD="$CMD --snapshot --snapshot-dir data/snapshots"
          echo "Weekly snapshot will be saved"
          
          echo "Running: $CMD"
          $CMD

      - name: Build history from snapshots
        run: |
          if [ -d "data/snapshots" ]; then
            python3 build_history.py
          else
            echo "No snapshots directory found, skipping history build"
          fi

      - name: Commit snapshots and history to repo
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add data files if they exist
          if [ -d "data/snapshots" ]; then
            git add data/snapshots/*.json 2>/dev/null || true
          fi
          if [ -f "data/history.json" ]; then
            git add data/history.json
          fi
          
          # Commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update historical snapshots [skip ci]"
            git push
            echo "Committed snapshot data to repo"
          fi

      - name: Save cache for next run
        uses: actions/cache/save@v4
        with:
          path: |
            terraform_providers.csv
            terraform_providers_details.json
            data/snapshots
            data/history.json
          key: provider-data-${{ hashFiles('terraform_providers.csv') }}

      - name: Generate HTML dashboard
        run: |
          echo "=== Debug: checking for data files ==="
          ls -la data/ 2>/dev/null || echo "No data/ folder"
          ls -la data/history.json 2>/dev/null || echo "No data/history.json"
          
          if [ -f "data/history.json" ]; then
            echo "Found history.json, passing explicitly to generator"
            python3 generate_html_dashboard.py terraform_providers.csv index.html data/history.json
          else
            echo "No history.json found, generating without history"
            python3 generate_html_dashboard.py terraform_providers.csv index.html
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Create pages artifact
        run: |
          mkdir -p _site/data
          cp index.html _site/
          cp terraform_providers.csv _site/
          cp terraform_providers_details.json _site/ 2>/dev/null || true
          cp data/history.json _site/data/ 2>/dev/null || true
          
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '_site'

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
